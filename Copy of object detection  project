{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM4SxlLg8EUka3mx2HJRkqV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ChcN9mIH0b3e","executionInfo":{"status":"ok","timestamp":1698572766244,"user_tz":-300,"elapsed":2047,"user":{"displayName":"Rida Zehra","userId":"04362398215956415855"}},"outputId":"8ac4358c-6c9b-4ddc-e79b-8d37f163120e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'yolov5'...\n","remote: Enumerating objects: 16026, done.\u001b[K\n","remote: Counting objects: 100% (59/59), done.\u001b[K\n","remote: Compressing objects: 100% (34/34), done.\u001b[K\n","remote: Total 16026 (delta 33), reused 41 (delta 25), pack-reused 15967\u001b[K\n","Receiving objects: 100% (16026/16026), 14.61 MiB | 25.83 MiB/s, done.\n","Resolving deltas: 100% (10999/10999), done.\n","/content/yolov5\n"]}],"source":["#clone yOLOv5 and\n","!git clone https://github.com/ultralytics/yolov5  # clone repo\n","%cd yolov5\n"]},{"cell_type":"code","source":["%pip install -qr requirements.txt # install dependencies\n","%pip install -q roboflow"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LkEAMEBH09-Y","executionInfo":{"status":"ok","timestamp":1698572815960,"user_tz":-300,"elapsed":19092,"user":{"displayName":"Rida Zehra","userId":"04362398215956415855"}},"outputId":"d0b6a2bc-8f22-4525-bebb-8f3c0e84e32b"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m644.8/644.8 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.2/72.2 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","lida 0.0.10 requires fastapi, which is not installed.\n","lida 0.0.10 requires kaleido, which is not installed.\n","lida 0.0.10 requires python-multipart, which is not installed.\n","lida 0.0.10 requires uvicorn, which is not installed.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["# Import necessary libraries\n","import torch\n","import os\n","from IPython.display import Image, clear_output  # to display images"],"metadata":{"id":"UBLnq1As1ZS0","executionInfo":{"status":"ok","timestamp":1698572904586,"user_tz":-300,"elapsed":431,"user":{"displayName":"Rida Zehra","userId":"04362398215956415855"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["#!pip install roboflow\n","\n","from roboflow import Roboflow\n","rf = Roboflow(api_key=\"081E2h5x03wwTzg1Omep\")\n","project = rf.workspace().project(\"road-turn-detections\")\n","dataset = project.version(2).download(\"yolov5\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YNBxPaG01iNe","executionInfo":{"status":"ok","timestamp":1698572945144,"user_tz":-300,"elapsed":4952,"user":{"displayName":"Rida Zehra","userId":"04362398215956415855"}},"outputId":"f27e4bc4-3b21-41fd-90e1-e5a76d3e8a2b"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["loading Roboflow workspace...\n","loading Roboflow project...\n"]},{"output_type":"stream","name":"stderr","text":["Downloading Dataset Version Zip in Road-Turn-Detections-2 to yolov5pytorch:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7147/7147 [00:00<00:00, 41620.25it/s]"]},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"stream","name":"stderr","text":["\n","Extracting Dataset Version Zip to Road-Turn-Detections-2 in yolov5pytorch:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 202/202 [00:00<00:00, 5343.23it/s]\n"]}]},{"cell_type":"code","source":["# Train the yOLOv5 model\n","!python train.py --img 640 --epochs 26 --data {dataset.location}/data.yaml --weights yolov5s.pt\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rcR7n2H_1p8z","executionInfo":{"status":"ok","timestamp":1698575725995,"user_tz":-300,"elapsed":110606,"user":{"displayName":"Rida Zehra","userId":"04362398215956415855"}},"outputId":"8639a9b4-ae8b-48c8-e5dc-9432c1c77e54"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-10-29 09:49:54.262123: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-10-29 09:49:54.262181: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-10-29 09:49:54.262258: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=/content/yolov5/Road-Turn-Detections-2/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=26, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n","\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 âœ…\n","YOLOv5 ğŸš€ v7.0-230-g53efd07 Python-3.10.12 torch-2.1.0+cu118 CPU\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n","\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 ğŸš€ runs in Comet\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","Overriding model.yaml nc=80 with nc=4\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n","  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n","  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n","  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n","  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n","  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n","  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n","  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n","  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n"," 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n"," 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n"," 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n"," 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n"," 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n","Model summary: 214 layers, 7030417 parameters, 7030417 gradients, 16.0 GFLOPs\n","\n","Transferred 343/349 items from yolov5s.pt\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolov5/Road-Turn-Detections-2/train/labels... 67 images, 0 backgrounds, 0 corrupt: 100% 67/67 [00:00<00:00, 857.85it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/yolov5/Road-Turn-Detections-2/train/labels.cache\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolov5/Road-Turn-Detections-2/valid/labels... 19 images, 0 backgrounds, 0 corrupt: 100% 19/19 [00:00<00:00, 479.45it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/yolov5/Road-Turn-Detections-2/valid/labels.cache\n","\n","\u001b[34m\u001b[1mAutoAnchor: \u001b[0m3.42 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset âœ…\n","Plotting labels to runs/train/exp2/labels.jpg... \n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mruns/train/exp2\u001b[0m\n","Starting training for 26 epochs...\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       0/25         0G     0.1185    0.03105    0.04533          4        640: 100% 5/5 [01:45<00:00, 21.01s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0% 0/1 [00:00<?, ?it/s]WARNING âš ï¸ NMS time limit 1.450s exceeded\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:10<00:00, 10.04s/it]\n","                   all         19         30    0.00104      0.054    0.00146   0.000225\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       1/25         0G     0.1037    0.03144    0.04175          5        640: 100% 5/5 [01:29<00:00, 17.80s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0% 0/1 [00:00<?, ?it/s]WARNING âš ï¸ NMS time limit 1.450s exceeded\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:09<00:00,  9.65s/it]\n","                   all         19         30    0.00104      0.054    0.00195   0.000477\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       2/25         0G     0.1031    0.03283    0.04256         11        640: 100% 5/5 [01:27<00:00, 17.53s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0% 0/1 [00:00<?, ?it/s]WARNING âš ï¸ NMS time limit 1.450s exceeded\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:10<00:00, 10.38s/it]\n","                   all         19         30     0.0016      0.158    0.00171   0.000257\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       3/25         0G    0.08725    0.02865    0.03949          9        640: 100% 5/5 [01:32<00:00, 18.41s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0% 0/1 [00:00<?, ?it/s]WARNING âš ï¸ NMS time limit 1.450s exceeded\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:09<00:00,  9.29s/it]\n","                   all         19         30    0.00172      0.212    0.00204   0.000291\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       4/25         0G    0.09483    0.03561    0.04195         16        640: 100% 5/5 [01:30<00:00, 18.07s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0% 0/1 [00:00<?, ?it/s]WARNING âš ï¸ NMS time limit 1.450s exceeded\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:10<00:00, 10.48s/it]\n","                   all         19         30    0.00227      0.322    0.00281   0.000559\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       5/25         0G    0.08325    0.02924    0.03835          4        640: 100% 5/5 [01:31<00:00, 18.26s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0% 0/1 [00:00<?, ?it/s]WARNING âš ï¸ NMS time limit 1.450s exceeded\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:10<00:00, 10.41s/it]\n","                   all         19         30    0.00265       0.44    0.00437   0.000928\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       6/25         0G    0.08287    0.03431    0.03949         11        640: 100% 5/5 [01:32<00:00, 18.53s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0% 0/1 [00:00<?, ?it/s]WARNING âš ï¸ NMS time limit 1.450s exceeded\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:09<00:00,  9.13s/it]\n","                   all         19         30     0.0024      0.384    0.00962    0.00227\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       7/25         0G    0.07809    0.03528     0.0393         12        640: 100% 5/5 [01:31<00:00, 18.39s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:09<00:00,  9.88s/it]\n","                   all         19         30    0.00401       0.68     0.0293    0.00869\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       8/25         0G    0.08268    0.03061    0.03888          6        640: 100% 5/5 [01:31<00:00, 18.36s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:09<00:00,  9.69s/it]\n","                   all         19         30    0.00468      0.772     0.0614     0.0141\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       9/25         0G    0.08111    0.03469    0.03795         19        640: 100% 5/5 [01:33<00:00, 18.71s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:09<00:00,  9.39s/it]\n","                   all         19         30    0.00486      0.795      0.139      0.038\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      10/25         0G    0.07448    0.02973    0.03578         10        640: 100% 5/5 [01:32<00:00, 18.45s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:09<00:00,  9.59s/it]\n","                   all         19         30    0.00552      0.901      0.241     0.0726\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      11/25         0G    0.06803    0.02838    0.03463          5        640: 100% 5/5 [01:31<00:00, 18.35s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:09<00:00,  9.52s/it]\n","                   all         19         30     0.0052      0.786      0.207     0.0604\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      12/25         0G    0.07061    0.03236     0.0365         11        640: 100% 5/5 [01:32<00:00, 18.58s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:08<00:00,  8.12s/it]\n","                   all         19         30    0.00568      0.923      0.227     0.0751\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      13/25         0G    0.07168    0.03543    0.03805         14        640: 100% 5/5 [01:32<00:00, 18.59s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:08<00:00,  8.03s/it]\n","                   all         19         30     0.0414      0.705      0.233     0.0925\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      14/25         0G    0.07071    0.03191    0.03295          9        640: 100% 5/5 [01:33<00:00, 18.72s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:09<00:00,  9.12s/it]\n","                   all         19         30      0.118       0.25       0.27      0.151\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      15/25         0G    0.06924    0.03811    0.03425         17        640: 100% 5/5 [01:34<00:00, 18.82s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:09<00:00,  9.17s/it]\n","                   all         19         30      0.905       0.25      0.238      0.103\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      16/25         0G    0.06869    0.03502    0.03542         14        640: 100% 5/5 [01:32<00:00, 18.58s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:08<00:00,  8.04s/it]\n","                   all         19         30      0.919        0.2      0.255       0.12\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      17/25         0G    0.06177    0.02779     0.0317          5        640: 100% 5/5 [01:33<00:00, 18.67s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:09<00:00,  9.24s/it]\n","                   all         19         30      0.945       0.18      0.302      0.218\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      18/25         0G    0.06195    0.03026    0.03146          7        640: 100% 5/5 [01:33<00:00, 18.75s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:09<00:00,  9.37s/it]\n","                   all         19         30      0.906       0.25      0.287      0.167\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      19/25         0G    0.05924    0.02975    0.03371          4        640: 100% 5/5 [01:34<00:00, 18.82s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:09<00:00,  9.16s/it]\n","                   all         19         30      0.944      0.177      0.289      0.201\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      20/25         0G    0.06814    0.03168    0.03078          7        640: 100% 5/5 [01:35<00:00, 19.06s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:08<00:00,  8.11s/it]\n","                   all         19         30          1      0.188      0.297      0.194\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      21/25         0G    0.06241    0.03532    0.03377         14        640: 100% 5/5 [01:31<00:00, 18.39s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:09<00:00,  9.19s/it]\n","                   all         19         30      0.945       0.18      0.265      0.221\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      22/25         0G    0.05816    0.03134    0.02907          7        640: 100% 5/5 [01:32<00:00, 18.56s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:08<00:00,  8.57s/it]\n","                   all         19         30          1       0.18      0.329      0.198\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      23/25         0G    0.06536    0.02985    0.03212         10        640: 100% 5/5 [01:31<00:00, 18.33s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:08<00:00,  8.98s/it]\n","                   all         19         30      0.995        0.2      0.318      0.121\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      24/25         0G    0.06133    0.02814    0.02891          5        640: 100% 5/5 [01:33<00:00, 18.65s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:09<00:00,  9.15s/it]\n","                   all         19         30      0.967        0.2        0.3      0.132\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      25/25         0G    0.06446    0.03319    0.03177         11        640: 100% 5/5 [01:33<00:00, 18.62s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:07<00:00,  7.93s/it]\n","                   all         19         30      0.955        0.2      0.288       0.13\n","\n","26 epochs completed in 0.750 hours.\n","Optimizer stripped from runs/train/exp2/weights/last.pt, 14.5MB\n","Optimizer stripped from runs/train/exp2/weights/best.pt, 14.5MB\n","\n","Validating runs/train/exp2/weights/best.pt...\n","Fusing layers... \n","Model summary: 157 layers, 7020913 parameters, 0 gradients, 15.8 GFLOPs\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:07<00:00,  8.00s/it]\n","                   all         19         30      0.945      0.182      0.302      0.218\n","             Left-Turn         19          6          1          0      0.107     0.0153\n","            Right-Turn         19          8          1          0      0.102      0.031\n","              straight         19         11          1          0     0.0702     0.0135\n","            unexpected         19          5      0.782      0.727      0.928      0.812\n","Results saved to \u001b[1mruns/train/exp2\u001b[0m\n"]}]},{"cell_type":"code","source":["# Run object detection on a validation dataset and save the detected images\n","!python detect.py --weights runs/train/exp/weights/best.pt --img 640 --conf 0.15 --source {dataset.location}/valid/images --save-txt --save-conf --save-crop\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8OYiuPOYAcAO","executionInfo":{"status":"ok","timestamp":1698575807566,"user_tz":-300,"elapsed":7678,"user":{"displayName":"Rida Zehra","userId":"04362398215956415855"}},"outputId":"2e9dbb88-c4e3-43ca-f0d6-ea9fc6422119"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mdetect: \u001b[0mweights=['runs/train/exp/weights/best.pt'], source=/content/yolov5/Road-Turn-Detections-2/valid/images, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.15, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=True, save_csv=False, save_conf=True, save_crop=True, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n","YOLOv5 ğŸš€ v7.0-230-g53efd07 Python-3.10.12 torch-2.1.0+cu118 CPU\n","\n","Traceback (most recent call last):\n","  File \"/content/yolov5/detect.py\", line 285, in <module>\n","    main(opt)\n","  File \"/content/yolov5/detect.py\", line 280, in main\n","    run(**vars(opt))\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n","    return func(*args, **kwargs)\n","  File \"/content/yolov5/detect.py\", line 101, in run\n","    model = DetectMultiBackend(weights, device=device, dnn=dnn, data=data, fp16=half)\n","  File \"/content/yolov5/models/common.py\", line 356, in __init__\n","    model = attempt_load(weights if isinstance(weights, list) else w, device=device, inplace=True, fuse=fuse)\n","  File \"/content/yolov5/models/experimental.py\", line 79, in attempt_load\n","    ckpt = torch.load(attempt_download(w), map_location='cpu')  # load\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 986, in load\n","    with _open_file_like(f, 'rb') as opened_file:\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 435, in _open_file_like\n","    return _open_file(name_or_buffer, mode)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 416, in __init__\n","    super().__init__(open(name, mode))\n","FileNotFoundError: [Errno 2] No such file or directory: 'runs/train/exp/weights/best.pt'\n"]}]},{"cell_type":"code","source":["# Create a directory to store the detected images\n","output_dir = \"/content/yolov5/detected_images\"\n","os.makedirs(output_dir, exist_ok=True)"],"metadata":{"id":"5_XqK3msAljg","executionInfo":{"status":"ok","timestamp":1698575838208,"user_tz":-300,"elapsed":380,"user":{"displayName":"Rida Zehra","userId":"04362398215956415855"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# Move the detected images to the output directory\n","!mv runs/detect/exp/* {output_dir}"],"metadata":{"id":"k8F-VI3sA0fS","executionInfo":{"status":"ok","timestamp":1698575905602,"user_tz":-300,"elapsed":2859,"user":{"displayName":"Rida Zehra","userId":"04362398215956415855"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# Display one of the detected images\n","display(Image(filename=f'{output_dir}/IMG_8740_JPG.rf.71206626f99b89bd95b83ec52982e87e.jpg', width=600))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":388},"id":"k8-6eBKtA7Tt","executionInfo":{"status":"error","timestamp":1698576032555,"user_tz":-300,"elapsed":1182,"user":{"displayName":"Rida Zehra","userId":"04362398215956415855"}},"outputId":"294cf32a-3025-4ebb-dcfb-635efd5c3268"},"execution_count":14,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-d12b480d8850>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Display one of the detected images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'{output_dir}/IMG_8740_JPG.rf.71206626f99b89bd95b83ec52982e87e.jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m600\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata)\u001b[0m\n\u001b[1;32m   1229\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretina\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretina\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1230\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munconfined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munconfined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1231\u001b[0;31m         super(Image, self).__init__(data=data, url=url, filename=filename, \n\u001b[0m\u001b[1;32m   1232\u001b[0m                 metadata=metadata)\n\u001b[1;32m   1233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename, metadata)\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1261\u001b[0m         \u001b[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1263\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1264\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretina\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retina_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_flags\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/yolov5/detected_images/IMG_8740_JPG.rf.71206626f99b89bd95b83ec52982e87e.jpg'"]}]}]}